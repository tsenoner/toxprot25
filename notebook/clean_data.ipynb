{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse / Extract consistent needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Kim Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_PATH = Path(\"..\") / \"data\"\n",
    "INPUT_PATH = DATA_PATH / \"raw\" / \"2023_Kim.xlsx\"\n",
    "OUTPUT_PATH = DATA_PATH / \"interim\" / \"toxprot_2017_old.csv\"\n",
    "\n",
    "# Define constants\n",
    "SHEET_NAME = \"ToxProt11.2017\"\n",
    "COLUMNS_TO_EXTRACT = [\n",
    "    \"Entry\",\n",
    "    \"Organism\",\n",
    "    \"Protein families\",\n",
    "    \"Length (aa)\",\n",
    "    \"Fragments\",\n",
    "    \"Toxic dose\",\n",
    "    \"PTM\",\n",
    "]\n",
    "\n",
    "# Read specific columns from the Excel sheet\n",
    "df = pd.read_excel(INPUT_PATH, sheet_name=SHEET_NAME, usecols=COLUMNS_TO_EXTRACT)\n",
    "\n",
    "# Rename 'Length (aa)' to 'Length' and 'Fragments' to 'Fragment'\n",
    "df = df.rename(columns={\"Length (aa)\": \"Length\", \"Fragments\": \"Fragment\"})\n",
    "\n",
    "# Ensure output directory exists and save as CSV\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "# Display information about the processed data\n",
    "print(f\"Data extracted and saved to {OUTPUT_PATH}\")\n",
    "print(f\"Shape of the extracted data: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(\"First few rows:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse SwissProt 2017-11 (extracted from [FTP](https://ftp.uniprot.org/pub/databases/uniprot/previous_major_releases/release-2017_11/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_protfams(df):\n",
    "    # Split on common delimiters and take first part\n",
    "    df[\"Protein families\"] = df[\"Protein families\"].str.split(r\"[.,;]\").str[0]\n",
    "    print(\n",
    "        f\"Unique protein families after splitting: {df['Protein families'].nunique()}\"\n",
    "    )\n",
    "\n",
    "    # Map of family name corrections\n",
    "    family_corrections = {\n",
    "        \"I1 superfamily\": \"Conotoxin I1 superfamily\",\n",
    "        \"O1 superfamily\": \"Conotoxin O1 superfamily\",\n",
    "        \"O2 superfamily\": \"Conotoxin O2 superfamily\",\n",
    "        \"E superfamily\": \"Conotoxin E superfamily\",\n",
    "        \"F superfamily\": \"Conotoxin F superfamily\",\n",
    "        \"Conotoxin M family\": \"Conotoxin M superfamily\",\n",
    "        \"Conotoxin B2 family\": \"Conotoxin B2 superfamily\",\n",
    "        \"Conotoxin O1 family\": \"Conotoxin O1 superfamily\",\n",
    "        \"Conotoxin O2 family\": \"Conotoxin O2 superfamily\",\n",
    "    }\n",
    "\n",
    "    # Apply all corrections at once\n",
    "    df[\"Protein families\"] = df[\"Protein families\"].replace(family_corrections)\n",
    "    print(\n",
    "        f\"Unique protein families after processing: {df['Protein families'].nunique()}\"\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the TSV file\n",
    "TSV_INPUT_PATH = DATA_PATH / \"interim\" / \"toxprot_2017.tsv\"\n",
    "CAV_OUTPUT_PATH = DATA_PATH / \"interim\" / \"toxprot_2017.csv\"\n",
    "\n",
    "# Define columns to extract with the correct column name for PTM\n",
    "COLUMNS_TO_EXTRACT = [\n",
    "    \"Entry\",\n",
    "    \"Organism\",\n",
    "    \"Organism (ID)\",\n",
    "    \"Protein families\",\n",
    "    \"Length\",\n",
    "    \"Fragment\",\n",
    "    \"Toxic dose\",\n",
    "    \"Post-translational modification\",  # Correct column name in the TSV file\n",
    "]\n",
    "\n",
    "# Read the TSV file\n",
    "df_tsv = pd.read_csv(TSV_INPUT_PATH, sep=\"\\t\", usecols=COLUMNS_TO_EXTRACT)\n",
    "\n",
    "# Rename 'Post-translational modification' to 'PTM' for consistency\n",
    "df_tsv = df_tsv.rename(columns={\"Post-translational modification\": \"PTM\"})\n",
    "\n",
    "# update protein families\n",
    "df_tsv = update_protfams(df_tsv)\n",
    "\n",
    "# Save as CSV\n",
    "df_tsv.to_csv(CAV_OUTPUT_PATH, index=False)\n",
    "\n",
    "# Display information about the processed data\n",
    "print(f\"TSV data extracted and saved to {CAV_OUTPUT_PATH}\")\n",
    "print(f\"Shape of the extracted TSV data: {df_tsv.shape}\")\n",
    "print(f\"Columns: {df_tsv.columns.tolist()}\")\n",
    "print(\"First few rows:\")\n",
    "display(df_tsv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse SwissProt 2025-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the TSV file\n",
    "TSV_INPUT_PATH = DATA_PATH / \"raw\" / \"202503_ToxProt.tsv\"\n",
    "CSV_OUTPUT_PATH = DATA_PATH / \"interim\" / \"toxprot_2025.csv\"\n",
    "\n",
    "# Define columns to extract with the correct column name for PTM\n",
    "COLUMNS_TO_EXTRACT = [\n",
    "    \"Entry\",\n",
    "    \"Organism\",\n",
    "    \"Organism (ID)\",\n",
    "    \"Protein families\",\n",
    "    \"Length\",\n",
    "    \"Fragment\",\n",
    "    \"Toxic dose\",\n",
    "    \"Post-translational modification\",  # Correct column name in the TSV file\n",
    "]\n",
    "\n",
    "# Read the TSV file\n",
    "df_tsv = pd.read_csv(TSV_INPUT_PATH, sep=\"\\t\", usecols=COLUMNS_TO_EXTRACT)\n",
    "\n",
    "# Rename 'Post-translational modification' to 'PTM' for consistency\n",
    "df_tsv = df_tsv.rename(columns={\"Post-translational modification\": \"PTM\"})\n",
    "\n",
    "# update protein families\n",
    "df_tsv = update_protfams(df_tsv)\n",
    "\n",
    "# Save as CSV\n",
    "df_tsv.to_csv(CSV_OUTPUT_PATH, index=False)\n",
    "\n",
    "# Display information about the processed data\n",
    "print(f\"TSV data extracted and saved to {CSV_OUTPUT_PATH}\")\n",
    "print(f\"Shape of the extracted TSV data: {df_tsv.shape}\")\n",
    "print(f\"Columns: {df_tsv.columns.tolist()}\")\n",
    "print(\"First few rows:\")\n",
    "display(df_tsv.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get taxonomy info\n",
    "Process taxonomic information from a CSV file using taxopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import taxopy\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def setup_db_paths():\n",
    "    \"\"\"Setup and return the database paths.\"\"\"\n",
    "    home_dir = Path.home() / \".cache\"\n",
    "    db_dir = home_dir / \"taxopy_db\"\n",
    "    db_dir.mkdir(parents=True, exist_ok=True)\n",
    "    nodes_file = db_dir / \"nodes.dmp\"\n",
    "    names_file = db_dir / \"names.dmp\"\n",
    "    merged_file = db_dir / \"merged.dmp\"\n",
    "\n",
    "    return db_dir, nodes_file, names_file, merged_file\n",
    "\n",
    "\n",
    "def initialize_taxdb():\n",
    "    \"\"\"Initialize and return the taxonomy database.\"\"\"\n",
    "    # Get the database paths\n",
    "    db_dir, nodes_file, names_file, merged_file = setup_db_paths()\n",
    "\n",
    "    if nodes_file.exists() and names_file.exists():\n",
    "        print(f\"Loading existing taxopy database from {db_dir}\")\n",
    "        taxdb = taxopy.TaxDb(\n",
    "            nodes_dmp=str(nodes_file),\n",
    "            names_dmp=str(names_file),\n",
    "            merged_dmp=str(merged_file),\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Downloading taxopy database to {db_dir}\")\n",
    "        taxdb = taxopy.TaxDb(taxdb_dir=str(db_dir), keep_files=True)\n",
    "\n",
    "    return taxdb\n",
    "\n",
    "\n",
    "def get_taxonomy_info(taxon_id, taxdb):\n",
    "    \"\"\"Get order, family, genus info for a taxon ID.\"\"\"\n",
    "    # Get the Taxon object\n",
    "    taxon = taxopy.Taxon(taxon_id, taxdb)\n",
    "\n",
    "    # Get the rank information\n",
    "    ranks = taxon.rank_name_dictionary\n",
    "\n",
    "    return {\n",
    "        \"taxon_name\": taxon.name,\n",
    "        \"order\": ranks.get(\"order\", \"\"),\n",
    "        \"family\": ranks.get(\"family\", \"\"),\n",
    "        \"genus\": ranks.get(\"genus\", \"\"),\n",
    "    }  # superkingdom, kingdom, phylum, class, order, family, genus, species\n",
    "\n",
    "\n",
    "def build_taxonomy_cache(df, taxdb):\n",
    "    \"\"\"Build a cache of taxonomy information for all unique organism IDs.\"\"\"\n",
    "    taxonomy_cache = {}\n",
    "    for taxon_id in df[\"Organism (ID)\"].unique():\n",
    "        if pd.notna(taxon_id):\n",
    "            taxonomy_cache[taxon_id] = get_taxonomy_info(taxon_id, taxdb)\n",
    "\n",
    "    return taxonomy_cache\n",
    "\n",
    "\n",
    "def add_taxonomy_columns(df, taxonomy_cache):\n",
    "    \"\"\"Add taxonomy columns to the dataframe.\"\"\"\n",
    "\n",
    "    # Create a mapping function that extracts all taxonomy info at once\n",
    "    def get_taxonomy_info(taxon_id):\n",
    "        cache_entry = taxonomy_cache.get(taxon_id, {})\n",
    "        return pd.Series(\n",
    "            {\n",
    "                \"Scientific_Name\": cache_entry.get(\"taxon_name\", \"\"),\n",
    "                \"Order\": cache_entry.get(\"order\", \"\"),\n",
    "                \"Family\": cache_entry.get(\"family\", \"\"),\n",
    "                \"Genus\": cache_entry.get(\"genus\", \"\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Apply the mapping function once to get all columns\n",
    "    taxonomy_df = df[\"Organism (ID)\"].apply(get_taxonomy_info)\n",
    "\n",
    "    # Concatenate the new columns with the original dataframe\n",
    "    return pd.concat([df, taxonomy_df], axis=1)\n",
    "\n",
    "\n",
    "def process_dataframe(input_path, output_path, taxdb):\n",
    "    \"\"\"Process the dataframe: load, add taxonomy, remove Organism column, save.\"\"\"\n",
    "    # Load the dataframe\n",
    "    print(f\"Loading data from {input_path}\")\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # Build the taxonomy cache\n",
    "    print(\"Building taxonomy cache...\")\n",
    "    taxonomy_cache = build_taxonomy_cache(df, taxdb)\n",
    "\n",
    "    # Add taxonomy columns\n",
    "    print(\"Adding taxonomy columns...\")\n",
    "    df = add_taxonomy_columns(df, taxonomy_cache)\n",
    "\n",
    "    # Remove the Organism column if it exists\n",
    "    if \"Organism\" in df.columns:\n",
    "        print(\"Removing 'Organism' column...\")\n",
    "        df = df.drop(columns=[\"Organism\"])\n",
    "\n",
    "    # Save the updated dataframe\n",
    "    print(f\"Saving processed data to {output_path}\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Processing complete. Data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing taxonomy database...\")\n",
    "taxdb = initialize_taxdb()\n",
    "\n",
    "# Process ToxProt 2017-11\n",
    "input_path = \"../data/interim/toxprot_2017.csv\"\n",
    "output_path = \"../data/processed/toxprot_2017.csv\"\n",
    "process_dataframe(input_path, output_path, taxdb)\n",
    "\n",
    "# Process ToxProt 2025-03\n",
    "input_path = \"../data/interim/toxprot_2025.csv\"\n",
    "output_path = \"../data/processed/toxprot_2025.csv\"\n",
    "process_dataframe(input_path, output_path, taxdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiate between marine and terrestrial organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the marine/terrestrial mapping\n",
    "mapping_path = \"../data/raw/marine_terrestrial.json\"\n",
    "\n",
    "# Load the marine/terrestrial mapping\n",
    "with open(mapping_path, \"r\") as f:\n",
    "    habitat_mapping = json.load(f)\n",
    "\n",
    "\n",
    "# Function to determine habitat based on order and genus\n",
    "def determine_habitat(row):\n",
    "    order = row[\"Order\"]\n",
    "    genus = row.get(\"Genus\", \"\")  # Get genus if available, otherwise empty string\n",
    "\n",
    "    # Check if order is in clear_orders\n",
    "    if order in habitat_mapping[\"clear_orders\"][\"terrestrial\"]:\n",
    "        return \"terrestrial\"\n",
    "    elif order in habitat_mapping[\"clear_orders\"][\"marine\"]:\n",
    "        return \"marine\"\n",
    "\n",
    "    # Check if order is in ambiguous_orders\n",
    "    if order in habitat_mapping[\"ambiguous_orders\"]:\n",
    "        # Check if genus is in the terrestrial list for this order\n",
    "        if genus in habitat_mapping[\"ambiguous_orders\"][order].get(\"terrestrial\", {}):\n",
    "            return \"terrestrial\"\n",
    "        # Check if genus is in the marine list for this order\n",
    "        elif genus in habitat_mapping[\"ambiguous_orders\"][order].get(\"marine\", {}):\n",
    "            return \"marine\"\n",
    "\n",
    "    # If we can't determine, return 'unknown'\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "# Process 2017 dataset\n",
    "csv_path_2017 = \"../data/processed/toxprot_2017.csv\"\n",
    "df_2017 = pd.read_csv(csv_path_2017)\n",
    "df_2017[\"Habitat\"] = df_2017.apply(determine_habitat, axis=1)\n",
    "print(\"ToxProt 2017 habitat distribution:\")\n",
    "print(df_2017[\"Habitat\"].value_counts())\n",
    "df_2017.to_csv(csv_path_2017, index=False)\n",
    "print(f\"Updated {csv_path_2017} with habitat information\")\n",
    "\n",
    "# Process 2025 dataset\n",
    "csv_path_2025 = \"../data/processed/toxprot_2025.csv\"\n",
    "df_2025 = pd.read_csv(csv_path_2025)\n",
    "df_2025[\"Habitat\"] = df_2025.apply(determine_habitat, axis=1)\n",
    "print(\"\\nToxProt 2025 habitat distribution:\")\n",
    "print(df_2025[\"Habitat\"].value_counts())\n",
    "df_2025.to_csv(csv_path_2025, index=False)\n",
    "print(f\"Updated {csv_path_2025} with habitat information\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
