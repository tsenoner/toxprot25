{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:37.470626Z",
     "start_time": "2025-05-16T13:30:37.468605Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106e714c962cb47a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:37.504926Z",
     "start_time": "2025-05-16T13:30:37.488634Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxprot_17 = pd.read_csv(\"../data/processed/toxprot_2017.csv\")\n",
    "toxprot_25 = pd.read_csv(\"../data/processed/toxprot_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80febbd656ba46d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:37.522572Z",
     "start_time": "2025-05-16T13:30:37.519453Z"
    }
   },
   "outputs": [],
   "source": [
    "toxprot_25[\"Protein families\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8e9f2ec5b1544",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:37.553620Z",
     "start_time": "2025-05-16T13:30:37.551226Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxprot_17[\"Fragment\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e5f34e7a312693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:37.593509Z",
     "start_time": "2025-05-16T13:30:37.590544Z"
    }
   },
   "outputs": [],
   "source": [
    "toxprot_25[\"Protein families\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f4df69304cebd2",
   "metadata": {},
   "source": [
    "### Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d6c566b53ed5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:37.799372Z",
     "start_time": "2025-05-16T13:30:37.664747Z"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.arange(1, 325, 25)\n",
    "\n",
    "bin_labels = [f\"{start}-{end - 1}\" for start, end in zip(bins[:-1], bins[1:])]\n",
    "bin_labels[-1] = \"300+\"\n",
    "\n",
    "lengths_25 = toxprot_25[\"Length\"]\n",
    "lengths_17 = toxprot_17[\"Length\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(lengths_25, bins=bins, color=plt.cm.tab10(1), label=\"toxprot_25\")\n",
    "plt.hist(lengths_17, bins=bins, color=plt.cm.tab10(0), label=\"toxprot_17\")\n",
    "\n",
    "plt.xlabel(\"Length Bins\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Overlaid Histogram of Sequence Lengths\")\n",
    "\n",
    "plt.xticks(bins[:-1] + 12.5, bin_labels, fontsize=9)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"../figures/overlaid_hist.png\", dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6f57a6a2dde19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:37.837609Z",
     "start_time": "2025-05-16T13:30:37.835370Z"
    }
   },
   "outputs": [],
   "source": [
    "toxprot_17[\"Fragment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2bcba752dd878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:37.899853Z",
     "start_time": "2025-05-16T13:30:37.896116Z"
    }
   },
   "outputs": [],
   "source": [
    "na_count_17 = toxprot_17[\"Protein families\"].isna().sum()  # Count NaN values\n",
    "total_count_17 = len(toxprot_17[\"Protein families\"])  # Total number of entries\n",
    "na_percentage_17 = (\n",
    "    (na_count_17 / total_count_17) * 100 if total_count_17 > 0 else 0\n",
    ")  # Calculate percentage\n",
    "unique_families_17 = len(toxprot_17[\"Protein families\"].dropna().unique())\n",
    "\n",
    "print(f\"N/A (NaN) Count: {na_count_17}\")\n",
    "print(f\"{unique_families_17}\")\n",
    "print(f\"N/A (NaN) Percentage: {na_percentage_17:.2f}%\")\n",
    "\n",
    "na_count_25 = toxprot_25[\"Protein families\"].isna().sum()  # Count NaN values\n",
    "total_count_25 = len(toxprot_25[\"Protein families\"])  # Total number of entries\n",
    "na_percentage_25 = (\n",
    "    (na_count_25 / total_count_25) * 100 if total_count_25 > 0 else 0\n",
    ")  # Calculate percentage\n",
    "unique_families_25 = len(toxprot_25[\"Protein families\"].dropna().unique())\n",
    "\n",
    "print(f\"N/A (NaN) Count: {na_count_25}\")\n",
    "print(f\"{unique_families_25}\")\n",
    "print(f\"N/A (NaN) Percentage: {na_percentage_25:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d0137e75e905b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.507086Z",
     "start_time": "2025-05-16T13:30:37.925700Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_families_per_dataset(df, column, top_n=15):\n",
    "    counts = df[column].value_counts()\n",
    "    top_counts = counts.nlargest(top_n)\n",
    "    other_count = counts.iloc[top_n:].sum()\n",
    "    nan_count = df[column].isna().sum()\n",
    "\n",
    "    top_counts[\"Other\"] = other_count\n",
    "    if nan_count > 0:\n",
    "        top_counts[\"NaN\"] = nan_count\n",
    "    return top_counts\n",
    "\n",
    "\n",
    "# Get top families per dataset\n",
    "top_17 = get_top_families_per_dataset(toxprot_17, \"Protein families\", top_n=15)\n",
    "top_25 = get_top_families_per_dataset(toxprot_25, \"Protein families\", top_n=15)\n",
    "\n",
    "# Build unified index\n",
    "top_17_sorted = top_17.sort_values(ascending=False)\n",
    "top_25_sorted = top_25.sort_values(ascending=False)\n",
    "all_families = top_17_sorted.index.to_list()\n",
    "for fam in top_25_sorted.index:\n",
    "    if fam not in all_families:\n",
    "        all_families.append(fam)\n",
    "\n",
    "# Create DataFrames\n",
    "df_stacked = pd.DataFrame(index=all_families)\n",
    "df_stacked[\"toxprot_17\"] = top_17.reindex(all_families).fillna(0)\n",
    "df_stacked[\"toxprot_25\"] = top_25.reindex(all_families).fillna(0)\n",
    "df_stacked_perc = df_stacked.div(df_stacked.sum()) * 100\n",
    "\n",
    "# Colors\n",
    "colors = plt.colormaps[\"tab20\"]\n",
    "families_no_nan_other = [f for f in all_families if f not in (\"Other\", \"NaN\")]\n",
    "color_map = {fam: colors(i) for i, fam in enumerate(families_no_nan_other)}\n",
    "color_map[\"Other\"] = colors(18)\n",
    "color_map[\"NaN\"] = colors(19)\n",
    "if \"Huwentoxin-1 family\" in color_map:\n",
    "    color_map[\"Neurotoxin 10 (Hwtx-1) family\"] = color_map[\"Huwentoxin-1 family\"]\n",
    "if \"Spider toxin CSTX superfamily\" in color_map:\n",
    "    color_map[\"Neurotoxin 19 (CSTX) family\"] = color_map[\n",
    "        \"Spider toxin CSTX superfamily\"\n",
    "    ]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(13, 9))\n",
    "\n",
    "# Bar 1 (toxprot_17)\n",
    "bottom = 0\n",
    "order_17 = df_stacked[\"toxprot_17\"].sort_values(ascending=False).index\n",
    "bars17 = []\n",
    "for fam in order_17:\n",
    "    pct = df_stacked_perc.at[fam, \"toxprot_17\"]\n",
    "    cnt = df_stacked.at[fam, \"toxprot_17\"]\n",
    "    if cnt > 0:\n",
    "        bar = ax.bar(\n",
    "            \"toxprot_17\", pct, bottom=bottom, color=color_map.get(fam, \"gray\")\n",
    "        )[0]\n",
    "        bars17.append((bar, fam, cnt, pct))\n",
    "    bottom += pct\n",
    "\n",
    "# Bar 2 (toxprot_25)\n",
    "bottom = 0\n",
    "order_25 = df_stacked[\"toxprot_25\"].sort_values(ascending=False).index\n",
    "bars25 = []\n",
    "for fam in order_25:\n",
    "    pct = df_stacked_perc.at[fam, \"toxprot_25\"]\n",
    "    cnt = df_stacked.at[fam, \"toxprot_25\"]\n",
    "    if cnt > 0:\n",
    "        bar = ax.bar(\n",
    "            \"toxprot_25\", pct, bottom=bottom, color=color_map.get(fam, \"gray\")\n",
    "        )[0]\n",
    "        bars25.append((bar, fam, cnt, pct))\n",
    "    bottom += pct\n",
    "\n",
    "# Add labels using each bar’s .get_x()/.get_width()\n",
    "for bar, fam, cnt, pct in bars17 + bars25:\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{fam}, {int(cnt)} ({pct:.1f}%)\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=9,\n",
    "        wrap=True,\n",
    "    )\n",
    "\n",
    "# Final formatting\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_title(\"100% Stacked Bar Chart of Protein Families\")\n",
    "ax.set_ylim(0, 100)\n",
    "ax.tick_params(axis=\"x\", labelsize=10)\n",
    "ax.tick_params(axis=\"y\", labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/stacked_bar_protfam.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1d52c0cb5e173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.534551Z",
     "start_time": "2025-05-16T13:30:38.528983Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure the 'Fragment' column is treated as a string\n",
    "toxprot_17[\"Fragment\"] = toxprot_17[\"Fragment\"].astype(str)\n",
    "toxprot_25[\"Fragment\"] = toxprot_25[\"Fragment\"].astype(str)\n",
    "\n",
    "# Count occurrences of \"fragment\" (case-insensitive)\n",
    "fragment_count_17 = (\n",
    "    toxprot_17[\"Fragment\"].str.contains(\"fragment\", case=False, na=False).sum()\n",
    ")\n",
    "total_count_17 = toxprot_17.shape[0]\n",
    "fragment_percentage_17 = (\n",
    "    (fragment_count_17 / total_count_17) * 100 if total_count_17 > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"Fragment Count 17: {fragment_count_17}\")\n",
    "print(f\"Fragment Percentage 17: {fragment_percentage_17:.2f}%\")\n",
    "\n",
    "fragment_count_25 = (\n",
    "    toxprot_25[\"Fragment\"].str.contains(\"fragment\", case=False, na=False).sum()\n",
    ")\n",
    "total_count_25 = toxprot_25.shape[0]\n",
    "fragment_percentage_25 = (\n",
    "    (fragment_count_25 / total_count_25) * 100 if total_count_25 > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"Fragment Count 25: {fragment_count_25}\")\n",
    "print(f\"Fragment Percentage 25: {fragment_percentage_25:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42783dd37d25d182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.549952Z",
     "start_time": "2025-05-16T13:30:38.547501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count occurrences where PTM is not NaN\n",
    "ptm_count_17 = toxprot_17[\"PTM\"].notna().sum()\n",
    "ptm_percentage_17 = (ptm_count_17 / total_count_17) * 100 if total_count_17 > 0 else 0\n",
    "\n",
    "print(f\"ptm Count (2017): {ptm_count_17}\")\n",
    "print(f\"ptm Percentage (2017): {ptm_percentage_17:.2f}%\")\n",
    "\n",
    "# Count occurrences where PTM is not NaN in 2025 datap\n",
    "ptm_count_25 = toxprot_25[\"PTM\"].notna().sum()\n",
    "ptm_percentage_25 = (ptm_count_25 / total_count_25) * 100 if total_count_25 > 0 else 0\n",
    "\n",
    "print(f\"ptm Count (2025): {ptm_count_25}\")\n",
    "print(f\"ptm Percentage (2025): {ptm_percentage_25:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1e700ca280061",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.567899Z",
     "start_time": "2025-05-16T13:30:38.565477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count occurrences where toxic is not NaN\n",
    "toxic_count_17 = toxprot_17[\"Toxic dose\"].notna().sum()\n",
    "toxic_percentage_17 = (\n",
    "    (toxic_count_17 / total_count_17) * 100 if total_count_17 > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"toxic Count (2017): {toxic_count_17}\")\n",
    "print(f\"toxic Percentage (2017): {toxic_percentage_17:.2f}%\")\n",
    "\n",
    "# Count occurrences where toxic is not NaN in 2025 data\n",
    "toxic_count_25 = toxprot_25[\"Toxic dose\"].notna().sum()\n",
    "toxic_percentage_25 = (\n",
    "    (toxic_count_25 / total_count_25) * 100 if total_count_25 > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"Toxic dose Count (2025): {toxic_count_25}\")\n",
    "print(f\"PTM Percentage (2025): {toxic_percentage_25:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd38b67876fdce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.584538Z",
     "start_time": "2025-05-16T13:30:38.582093Z"
    }
   },
   "outputs": [],
   "source": [
    "len(toxprot_17[\"Species\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a85401662e337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.726835Z",
     "start_time": "2025-05-16T13:30:38.599021Z"
    }
   },
   "outputs": [],
   "source": [
    "cell_text = [\n",
    "    [total_count_17, total_count_25],\n",
    "    [unique_families_17, unique_families_25],\n",
    "    [\n",
    "        f\"{na_count_17} ({na_percentage_17:.2f}%)\",\n",
    "        f\"{na_count_25} ({na_percentage_25:.2f}%)\",\n",
    "    ],\n",
    "    [\n",
    "        f\"{fragment_count_17} ({fragment_percentage_17:.2f}%)\",\n",
    "        f\"{fragment_count_25} ({fragment_percentage_25:.2f}%)\",\n",
    "    ],\n",
    "    [\n",
    "        f\"{ptm_count_17} ({ptm_percentage_17:.2f}%)\",\n",
    "        f\"{ptm_count_25} ({ptm_percentage_25:.2f}%)\",\n",
    "    ],\n",
    "    [\n",
    "        f\"{toxic_count_17} ({toxic_percentage_17:.2f}%)\",\n",
    "        f\"{toxic_count_25} ({toxic_percentage_25:.2f}%)\",\n",
    "    ],\n",
    "    [\n",
    "        len(toxprot_17[\"Species\"].unique()),\n",
    "        len(toxprot_25[\"Species\"].unique()),\n",
    "    ],\n",
    "    [len(toxprot_17[\"Order\"].unique()), len(toxprot_25[\"Order\"].unique())],\n",
    "]\n",
    "row_headers = [\n",
    "    \"Total entry count\",\n",
    "    'unique Protein families count\\n(collapsed after first \",\")',\n",
    "    \"N/A protein family count\",\n",
    "    \"Entries that are Fragments\",\n",
    "    \"Entries with PTM annotation\",\n",
    "    \"Entries with toxic dose annotation\",\n",
    "    \"Number of species\",\n",
    "    \"Number of order\",\n",
    "]\n",
    "column_headers = [\"2017\", \"2025\"]\n",
    "\n",
    "rcolors = plt.cm.BuPu(np.full(len(row_headers), 0.1))\n",
    "ccolors = plt.cm.BuPu(np.full(len(column_headers), 0.1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.axis(\"tight\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "the_table = plt.table(\n",
    "    cellText=cell_text,\n",
    "    rowLabels=row_headers,\n",
    "    rowColours=rcolors,\n",
    "    rowLoc=\"center\",\n",
    "    colColours=ccolors,\n",
    "    colLabels=column_headers,\n",
    "    cellLoc=\"center\",\n",
    "    loc=\"center\",\n",
    ")\n",
    "\n",
    "table_props = the_table.properties()\n",
    "cells = table_props[\"children\"]\n",
    "for cell in cells:\n",
    "    cell.set_height(0.14)\n",
    "\n",
    "for cell in cells:\n",
    "    cell.set_fontsize(10)\n",
    "\n",
    "for i, key in enumerate(the_table._cells):\n",
    "    if key[0] == 0:  # Column labels\n",
    "        the_table._cells[key].set_fontsize(15)\n",
    "    if key[1] == 0:  # Row labels\n",
    "        the_table._cells[key].set_fontsize(15)\n",
    "\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n",
    "\n",
    "plt.savefig(\"../figures/table.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d9fa70b4d09f94c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.741894Z",
     "start_time": "2025-05-16T13:30:38.739271Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.graph_objects as go\n",
    "# from pathlib import Path\n",
    "#\n",
    "# # Ensure output folder exists\n",
    "# OUT = Path(\"out\")\n",
    "# OUT.mkdir(exist_ok=True)\n",
    "#\n",
    "# # 1) Load & extract primary families\n",
    "# tox17 = pd.read_csv(\"../data/processed/toxprot_2017.csv\")\n",
    "# tox25 = pd.read_csv(\"../data/processed/toxprot_2025.csv\")\n",
    "#\n",
    "# tox17[\"Family_2017\"] = (\n",
    "#     tox17[\"Protein families\"].fillna(\"\")\n",
    "#          .str.split(r\"\\.\", n=1, regex=True).str[0]\n",
    "# )\n",
    "# tox25[\"Family_2025\"] = (\n",
    "#     tox25[\"Protein families\"].fillna(\"\")\n",
    "#          .str.split(r\"[,;]\", n=1, regex=True).str[0]\n",
    "# )\n",
    "#\n",
    "# # 2) Merge on Entry (inner join)\n",
    "# df17 = tox17[[\"Entry\",\"Family_2017\"]]\n",
    "# df25 = tox25[[\"Entry\",\"Family_2025\"]]\n",
    "# merged = pd.merge(df17, df25, on=\"Entry\", how=\"inner\")\n",
    "#\n",
    "# # 3) Count every transition (self‐flows included)\n",
    "# flows = (\n",
    "#     merged\n",
    "#       .groupby([\"Family_2017\",\"Family_2025\"])\n",
    "#       .size()\n",
    "#       .reset_index(name=\"value\")\n",
    "# )\n",
    "#\n",
    "# # 4) Find global top-10 in each year\n",
    "# counts_17 = merged[\"Family_2017\"].value_counts()\n",
    "# counts_25 = merged[\"Family_2025\"].value_counts()\n",
    "# top10_17  = counts_17.nlargest(10).index.tolist()\n",
    "# top10_25  = counts_25.nlargest(10).index.tolist()\n",
    "#\n",
    "# # 5) Bin into top-10 / Other / nan\n",
    "# def bin_family(x, top10, tag):\n",
    "#     if x == \"\" or pd.isna(x):\n",
    "#         return f\"nan ({tag})\"\n",
    "#     if x in top10:\n",
    "#         return x\n",
    "#     return f\"Other ({tag})\"\n",
    "#\n",
    "# flows[\"old_bin\"] = flows[\"Family_2017\"].apply(lambda x: bin_family(x, top10_17, \"2017\"))\n",
    "# flows[\"new_bin\"] = flows[\"Family_2025\"].apply(lambda x: bin_family(x, top10_25, \"2025\"))\n",
    "#\n",
    "# binned = (\n",
    "#     flows\n",
    "#       .groupby([\"old_bin\",\"new_bin\"])[\"value\"]\n",
    "#       .sum()\n",
    "#       .reset_index()\n",
    "# )\n",
    "#\n",
    "# # 6) Build node list (old on left, new on right)\n",
    "# old_nodes = top10_17 + [\"Other (2017)\", \"nan (2017)\"]\n",
    "# new_nodes = top10_25 + [\"Other (2025)\", \"nan (2025)\"]\n",
    "# labels   = old_nodes + new_nodes\n",
    "# idx_map  = {lab: i for i, lab in enumerate(labels)}\n",
    "#\n",
    "# binned[\"source\"] = binned[\"old_bin\"].map(idx_map)\n",
    "# binned[\"target\"] = binned[\"new_bin\"].map(idx_map)\n",
    "#\n",
    "# # 7) Compute even y-positions for each node\n",
    "# n_left  = len(old_nodes)\n",
    "# n_right = len(new_nodes)\n",
    "# y_left  = np.linspace(0, 1, n_left)\n",
    "# y_right = np.linspace(0, 1, n_right)\n",
    "# node_x  = [0.0]*n_left + [1.0]*n_right\n",
    "# node_y  = np.concatenate([y_left, y_right]).tolist()\n",
    "#\n",
    "# # 8) Create the Sankey with fixed arrangement\n",
    "# fig = go.Figure(go.Sankey(\n",
    "#     arrangement=\"fixed\",\n",
    "#     orientation=\"h\",\n",
    "#     node=dict(\n",
    "#         label=labels,\n",
    "#         x=node_x,\n",
    "#         y=node_y,\n",
    "#         pad=10,\n",
    "#         thickness=30,\n",
    "#         line=dict(color=\"black\", width=0.5),\n",
    "#     ),\n",
    "#     link=dict(\n",
    "#         source=binned[\"source\"],\n",
    "#         target=binned[\"target\"],\n",
    "#         value=binned[\"value\"],\n",
    "#         color='rgba(0,0,0,0.2)',        # light‐gray fill\n",
    "#         line=dict(color=\"black\", width=0.5),\n",
    "#     )\n",
    "# ))\n",
    "#\n",
    "# # 9) Bump fonts for print\n",
    "# fig.update_layout(\n",
    "#     title_text=\"Protein-family flows, 2017 → 2025 (top-10 bins)\",\n",
    "#     font=dict(size=14, family=\"Arial\"),\n",
    "#     title_font_size=18,\n",
    "#     width=1200,\n",
    "#     height=800,\n",
    "#     margin=dict(l=50, r=50, t=80, b=50),\n",
    "# )\n",
    "#\n",
    "# # Show interactive for quick check\n",
    "# fig.show()\n",
    "#\n",
    "# print(f\"Static Sankey exported to: {OUT/'sankey_static.png'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af34085d7e9cf9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.756964Z",
     "start_time": "2025-05-16T13:30:38.755812Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd295623b57854b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.771088Z",
     "start_time": "2025-05-16T13:30:38.769780Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be623280d8aeaa35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T13:30:38.785067Z",
     "start_time": "2025-05-16T13:30:38.783831Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
